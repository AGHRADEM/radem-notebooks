{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>bin</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-01 00:00:56</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-01 00:00:56</td>\n",
       "      <td>2</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-01 00:00:56</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-01 00:00:56</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-01 00:00:56</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209548</th>\n",
       "      <td>2024-05-07 15:36:46</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209549</th>\n",
       "      <td>2024-05-07 15:36:46</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209550</th>\n",
       "      <td>2024-05-07 15:36:46</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209551</th>\n",
       "      <td>2024-05-07 15:36:46</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209552</th>\n",
       "      <td>2024-05-07 15:36:46</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3209553 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time  bin  value\n",
       "0        2023-09-01 00:00:56    1      6\n",
       "1        2023-09-01 00:00:56    2    222\n",
       "2        2023-09-01 00:00:56    3     27\n",
       "3        2023-09-01 00:00:56    4     21\n",
       "4        2023-09-01 00:00:56    5     18\n",
       "...                      ...  ...    ...\n",
       "3209548  2024-05-07 15:36:46    4     25\n",
       "3209549  2024-05-07 15:36:46    5     19\n",
       "3209550  2024-05-07 15:36:46    6     29\n",
       "3209551  2024-05-07 15:36:46    7     25\n",
       "3209552  2024-05-07 15:36:46    9      0\n",
       "\n",
       "[3209553 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FixMe: This is a strange way of loading this `.csv` file\n",
    "protons_df = [pd.read_csv(path) for path in glob.glob(\"../data/csv/protons_2024*.csv\")][0]\n",
    "protons_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-01 00:00:56</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-09-01 00:01:56</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023-09-01 00:02:56</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2023-09-01 00:03:56</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2023-09-01 00:04:56</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209515</th>\n",
       "      <td>2024-05-07 15:32:46</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209524</th>\n",
       "      <td>2024-05-07 15:33:46</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209533</th>\n",
       "      <td>2024-05-07 15:34:46</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209542</th>\n",
       "      <td>2024-05-07 15:35:46</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3209545</th>\n",
       "      <td>2024-05-07 15:36:46</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356617 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time  value\n",
       "0        2023-09-01 00:00:56      6\n",
       "16       2023-09-01 00:01:56      9\n",
       "25       2023-09-01 00:02:56      4\n",
       "35       2023-09-01 00:03:56      4\n",
       "43       2023-09-01 00:04:56      7\n",
       "...                      ...    ...\n",
       "3209515  2024-05-07 15:32:46      3\n",
       "3209524  2024-05-07 15:33:46      2\n",
       "3209533  2024-05-07 15:34:46      6\n",
       "3209542  2024-05-07 15:35:46      5\n",
       "3209545  2024-05-07 15:36:46      6\n",
       "\n",
       "[356617 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protons_bin_1 = protons_df[protons_df['bin'] == 1]\n",
    "protons_bin_1.drop('bin', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Rewrite with validation and more types. For example a pd.Series instead of pd.DataFrame\n",
    "# TODO: Different naming for `sigma`, `cusum_window` and `channel`\n",
    "def find_onset(series: pd.Series, background_mu_sigma: Tuple[float, float], cusum_window:int=30):\n",
    "    # TODO: Parametrize outside of function\n",
    "    sigma_multiplier = 2\n",
    "    bg_mean, bg_sigma = background_mu_sigma\n",
    "    uncertainty_limit = bg_mean + sigma_multiplier * bg_sigma\n",
    "\n",
    "    # FixMe: Floating point comparison\n",
    "    if bg_mean == uncertainty_limit:\n",
    "        raise ValueError(\"\"\"Background radiation mean value and uncertainty limit are equal.\n",
    "                            Control parameter k cannot be computed.\"\"\")\n",
    "\n",
    "    k = (uncertainty_limit - bg_mean) / (np.log1p(uncertainty_limit) - np.log1p(bg_mean))\n",
    "    hastiness = 1 if k < 1.0 else 2\n",
    "\n",
    "    alert = 0\n",
    "    previous_cusum, cusum = 0, 0\n",
    "\n",
    "    onset_time = None\n",
    "    for i in range(1, len(series)):\n",
    "        normalized_flux = (series.iloc[i] - bg_mean) / bg_sigma\n",
    "        previous_cusum, cusum = cusum, np.max(0, normalized_flux - round(k) + previous_cusum)\n",
    "        alert = alert + 1 if cusum > hastiness else 0\n",
    "\n",
    "        if alert == cusum_window:\n",
    "            onset_time = series.index[i - alert]\n",
    "            break\n",
    "        \n",
    "    return onset_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux, onset_stats, onset_found, peak_flux, peak_time, fig, bg_mean = Event_onset.find_onset(viewing=w.view_drop.value, background_range=background_range, channels=channels,\n",
    "                                                                                            resample_period=averaging, yscale='log', cusum_window=30, xlim=plot_range)\n",
    "onset = onset_stats[-1]\n",
    "peak_flux = peak_flux.values[0]\n",
    "output = Event_onset.output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onset_determination(self, ma_sigma, flux_series, cusum_window, bg_end_time):\n",
    "\n",
    "        flux_series = flux_series[bg_end_time:]\n",
    "\n",
    "        # assert date and the starting index of the averaging process\n",
    "        date = flux_series.index\n",
    "        ma = ma_sigma[0]\n",
    "        sigma = ma_sigma[1]\n",
    "        md = ma + self.x_sigma*sigma\n",
    "\n",
    "        # k may get really big if sigma is large in comparison to mean\n",
    "        try:\n",
    "\n",
    "            k = (md-ma)/(np.log(md)-np.log(ma))\n",
    "            k_round = round(k/sigma)\n",
    "\n",
    "        except ValueError:\n",
    "\n",
    "            # First ValueError I encountered was due to ma=md=2.0 -> k = \"0/0\"\n",
    "            k_round = 1\n",
    "\n",
    "        # choose h, the variable dictating the \"hastiness\" of onset alert\n",
    "        if k < 1.0:\n",
    "\n",
    "            h = 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            h = 2\n",
    "\n",
    "        alert = 0\n",
    "        cusum = np.zeros(len(flux_series))\n",
    "        norm_channel = np.zeros(len(flux_series))\n",
    "\n",
    "        # set the onset as default to be NaT (Not a Date)\n",
    "        onset_time = pd.NaT\n",
    "\n",
    "        for i in range(1, len(cusum)):\n",
    "\n",
    "            # normalize the observed flux\n",
    "            norm_channel[i] = (flux_series.iloc[i]-ma)/sigma\n",
    "\n",
    "            # calculate the value for ith cusum entry\n",
    "            cusum[i] = max(0, norm_channel[i] - k_round + cusum[i-1])\n",
    "\n",
    "            # check if cusum[i] is above threshold h,\n",
    "            # if it is -> increment alert\n",
    "            if cusum[i] > h:\n",
    "\n",
    "                alert = alert + 1\n",
    "\n",
    "            else:\n",
    "\n",
    "                alert = 0\n",
    "\n",
    "            # cusum_window(default:30) subsequent increments to alert\n",
    "            # means that the onset was found\n",
    "            if alert == cusum_window:\n",
    "\n",
    "                onset_time = date[i - alert]\n",
    "                break\n",
    "\n",
    "        # ma = mu_a = background average\n",
    "        # md = mu_d = background average + 2*sigma\n",
    "        # k_round = integer value of k, that is the reference value to\n",
    "        # poisson cumulative sum\n",
    "        # h = 1 or 2,describes the hastiness of onset alert\n",
    "        # onset_time = the time of the onset\n",
    "        # S = the cusum function\n",
    "\n",
    "        return [ma, md, k_round, norm_channel, cusum, onset_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onset_analysis(self, df_flux, windowstart, windowlen, windowrange, channels_dict,\n",
    "                       channel='flux', cusum_window=30, yscale='log',\n",
    "                       ylim=None, xlim=None):\n",
    "\n",
    "        self.print_info(\"Energy channels\", channels_dict)\n",
    "        spacecraft = self.spacecraft.upper()\n",
    "        sensor = self.sensor.upper()\n",
    "\n",
    "        color_dict = {\n",
    "            'onset_time': '#e41a1c',\n",
    "            'bg_mean': '#e41a1c',\n",
    "            'flux_peak': '#1a1682',\n",
    "            'bg': '#de8585'\n",
    "        }\n",
    "\n",
    "        if self.spacecraft == 'solo':\n",
    "            flux_series = df_flux[channel]\n",
    "        if self.spacecraft[:2].lower() == 'st':\n",
    "            flux_series = df_flux  # [channel]'\n",
    "        if self.spacecraft.lower() == 'soho':\n",
    "            flux_series = df_flux  # [channel]\n",
    "        if self.spacecraft.lower() == 'wind':\n",
    "            flux_series = df_flux  # [channel]\n",
    "        if self.spacecraft.lower() == 'psp':\n",
    "            flux_series = df_flux[channel]\n",
    "        if self.spacecraft.lower() == 'bepi':\n",
    "            flux_series = df_flux  # [channel]\n",
    "        date = flux_series.index\n",
    "\n",
    "        if ylim is None:\n",
    "\n",
    "            ylim = [np.nanmin(flux_series[flux_series > 0]/2),\n",
    "                    np.nanmax(flux_series) * 3]\n",
    "\n",
    "        # windowrange is by default None, and then we define the start and stop with integer hours\n",
    "        if windowrange is None:\n",
    "            # dates for start and end of the averaging processes\n",
    "            avg_start = date[0] + datetime.timedelta(hours=windowstart)\n",
    "            # ending time is starting time + a given timedelta in hours\n",
    "            avg_end = avg_start + datetime.timedelta(hours=windowlen)\n",
    "\n",
    "        else:\n",
    "            avg_start, avg_end = windowrange[0], windowrange[1]\n",
    "\n",
    "        if xlim is None:\n",
    "\n",
    "            xlim = [date[0], date[-1]]\n",
    "\n",
    "        else:\n",
    "\n",
    "            df_flux = df_flux[xlim[0]:xlim[-1]]\n",
    "\n",
    "        # onset not yet found\n",
    "        onset_found = False\n",
    "        background_stats = self.mean_value(avg_start, avg_end, flux_series)\n",
    "        onset_stats =\\\n",
    "            self.onset_determination(background_stats, flux_series,\n",
    "                                     cusum_window, avg_end)\n",
    "\n",
    "        if not isinstance(onset_stats[-1], pd._libs.tslibs.nattype.NaTType):\n",
    "\n",
    "            onset_found = True\n",
    "\n",
    "        if self.spacecraft == 'solo':\n",
    "            df_flux_peak = df_flux[df_flux[channel] == df_flux[channel].max()]\n",
    "        if self.spacecraft[:2].lower() == 'st':\n",
    "            df_flux_peak = df_flux[df_flux == df_flux.max()]\n",
    "        if self.spacecraft == 'soho':\n",
    "            df_flux_peak = df_flux[df_flux == df_flux.max()]\n",
    "        if self.spacecraft == 'wind':\n",
    "            df_flux_peak = df_flux[df_flux == df_flux.max()]\n",
    "        if self.spacecraft == 'psp':\n",
    "            # df_flux_peak = df_flux[df_flux == df_flux.max()]\n",
    "            df_flux_peak = df_flux[df_flux[channel] == df_flux[channel].max()]\n",
    "        if self.spacecraft == 'bepi':\n",
    "            df_flux_peak = df_flux[df_flux == df_flux.max()]\n",
    "            # df_flux_peak = df_flux[df_flux[channel] == df_flux[channel].max()]\n",
    "        self.print_info(\"Flux peak\", df_flux_peak)\n",
    "        self.print_info(\"Onset time\", onset_stats[-1])\n",
    "        self.print_info(\"Mean of background intensity\",\n",
    "                        background_stats[0])\n",
    "        self.print_info(\"Std of background intensity\",\n",
    "                        background_stats[1])\n",
    "\n",
    "        # Before starting the plot, save the original rcParam options and update to new ones\n",
    "        original_rcparams = self.save_and_update_rcparams(\"onset_tool\")\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(flux_series.index, flux_series.values, ds='steps-mid')\n",
    "\n",
    "        # CUSUM and norm datapoints in plots.\n",
    "        '''\n",
    "        ax.scatter(flux_series.index, onset_stats[-3], s=1,\n",
    "                   color='darkgreen', alpha=0.7, label='norm')\n",
    "        ax.scatter(flux_series.index, onset_stats[-2], s=3,\n",
    "                   c='maroon', label='CUSUM')\n",
    "        '''\n",
    "\n",
    "        # onset time\n",
    "        if onset_found:\n",
    "\n",
    "            # Onset time line\n",
    "            ax.axvline(onset_stats[-1], linewidth=1.5,\n",
    "                       color=color_dict['onset_time'], linestyle='-',\n",
    "                       label=\"Onset time\")\n",
    "\n",
    "        # Flux peak line (first peak only, if there's multiple)\n",
    "        try:\n",
    "            ax.axvline(df_flux_peak.index[0], linewidth=1.5,\n",
    "                       color=color_dict['flux_peak'], linestyle='-',\n",
    "                       label=\"Peak time\")\n",
    "\n",
    "        except IndexError:\n",
    "            exceptionmsg = \"IndexError! Maybe you didn't adjust background_range or plot_range correctly?\"\n",
    "            raise Exception(exceptionmsg)\n",
    "\n",
    "        # background mean\n",
    "        ax.axhline(onset_stats[0], linewidth=2,\n",
    "                   color=color_dict['bg_mean'], linestyle='--',\n",
    "                   label=\"Mean of background\")\n",
    "\n",
    "        # background mean + 2*std\n",
    "        ax.axhline(onset_stats[1], linewidth=2,\n",
    "                   color=color_dict['bg_mean'], linestyle=':',\n",
    "                   label=f\"Mean + {str(self.x_sigma)} * std of background\")\n",
    "\n",
    "        # Background shaded area\n",
    "        ax.axvspan(avg_start, avg_end, color=color_dict['bg'],\n",
    "                   label=\"Background\", alpha=0.5)\n",
    "\n",
    "        # ax.set_xlabel(\"Time [HH:MM \\nYYYY-mm-dd]\", fontsize=16)\n",
    "        ax.set_ylabel(r\"Intensity [1/(cm$^{2}$ sr s MeV)]\", fontsize=16)\n",
    "        ax.yaxis.set_major_locator(plt.MaxNLocator(4))\n",
    "\n",
    "        # figure limits and scale\n",
    "        plt.ylim(ylim)\n",
    "        plt.xlim(xlim[0], xlim[1])\n",
    "        plt.yscale(yscale)\n",
    "        plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2),\n",
    "                   fancybox=True, shadow=False, ncol=3, fontsize=16)\n",
    "\n",
    "        # tickmarks, their size etc...\n",
    "        plt.tick_params(which='major', length=5, width=1.5, labelsize=16)\n",
    "        plt.tick_params(which='minor', length=4, width=1)\n",
    "\n",
    "        # date tick locator and formatter\n",
    "        ax.xaxis_date()\n",
    "        # ax.xaxis.set_major_locator(ticker.MaxNLocator(9))\n",
    "        # utc_dt_format1 = DateFormatter('%H:%M \\n%Y-%m-%d')\n",
    "        utc_dt_format1 = DateFormatter('%H:%M\\n%b %d\\n%Y')\n",
    "        ax.xaxis.set_major_formatter(utc_dt_format1)\n",
    "\n",
    "        if self.species == 'e':\n",
    "\n",
    "            s_identifier = 'electrons'\n",
    "\n",
    "        if self.species in ['p', 'i']:\n",
    "\n",
    "            if ((spacecraft == 'sta' and sensor == 'sept') or (spacecraft == 'solo' and sensor == 'ept')):\n",
    "\n",
    "                s_identifier = 'ions'\n",
    "\n",
    "            else:\n",
    "\n",
    "                s_identifier = 'protons'\n",
    "\n",
    "        self.print_info(\"Particle species\", s_identifier)\n",
    "\n",
    "        if (self.viewing_used != '' and self.viewing_used is not None):\n",
    "\n",
    "            plt.title(f\"{spacecraft}/{sensor} {channels_dict} {s_identifier}\\n\"\n",
    "                      f\"{self.averaging_used} averaging, viewing: \"\n",
    "                      f\"{self.viewing_used.upper()}\")\n",
    "\n",
    "        else:\n",
    "\n",
    "            plt.title(f\"{spacecraft}/{sensor} {channels_dict} {s_identifier}\\n\"\n",
    "                      f\"{self.averaging_used} averaging\")\n",
    "\n",
    "        fig.set_size_inches(16, 8)\n",
    "\n",
    "        # Onset label\n",
    "        if onset_found:\n",
    "\n",
    "            if (self.spacecraft == 'solo' or self.spacecraft == 'psp'):\n",
    "                plabel = AnchoredText(f\"Onset time: {str(onset_stats[-1])[:19]}\\n\"\n",
    "                                      f\"Peak flux: {df_flux_peak['flux'].iloc[0]:.2E}\",\n",
    "                                      prop=dict(size=13), frameon=True,\n",
    "                                      loc=(4))\n",
    "            # if(self.spacecraft[:2].lower() == 'st' or self.spacecraft == 'soho' or self.spacecraft == 'wind'):\n",
    "            else:\n",
    "                plabel = AnchoredText(f\"Onset time: {str(onset_stats[-1])[:19]}\\n\"\n",
    "                                      f\"Peak flux: {df_flux_peak.values[0]:.2E}\",\n",
    "                                      prop=dict(size=13), frameon=True,\n",
    "                                      loc=(4))\n",
    "\n",
    "        else:\n",
    "\n",
    "            plabel = AnchoredText(\"No onset found\",\n",
    "                                  prop=dict(size=13), frameon=True,\n",
    "                                  loc=(4))\n",
    "\n",
    "        plabel.patch.set_boxstyle(\"round, pad=0., rounding_size=0.2\")\n",
    "        plabel.patch.set_linewidth(2.0)\n",
    "\n",
    "        # Background label\n",
    "        blabel = AnchoredText(f\"Background:\\n{avg_start} - {avg_end}\",\n",
    "                              prop=dict(size=13), frameon=True,\n",
    "                              loc='upper left')\n",
    "        blabel.patch.set_boxstyle(\"round, pad=0., rounding_size=0.2\")\n",
    "        blabel.patch.set_linewidth(2.0)\n",
    "\n",
    "        # Energy and species label\n",
    "        '''\n",
    "        eslabel = AnchoredText(f\"{channels_dict} {s_identifier}\",\n",
    "                               prop=dict(size=13), frameon=True,\n",
    "                               loc='lower left')\n",
    "        eslabel.patch.set_boxstyle(\"round, pad=0., rounding_size=0.2\")\n",
    "        eslabel.patch.set_linewidth(2.0)\n",
    "        '''\n",
    "\n",
    "        ax.add_artist(plabel)\n",
    "        ax.add_artist(blabel)\n",
    "        # ax.add_artist(eslabel)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Finally reset matplotlib rcParams to what they were before plotting\n",
    "        rcParams.update(original_rcparams)\n",
    "\n",
    "        return flux_series, onset_stats, onset_found, df_flux_peak, df_flux_peak.index[0], fig, background_stats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " def find_onset_backup(self, viewing, bg_start=None, bg_length=None, background_range=None, resample_period=None,\n",
    "                   channels=[0, 1], yscale='log', cusum_window=30, xlim=None, x_sigma=2):\n",
    "        \"\"\"\n",
    "        This method runs Poisson-CUSUM onset analysis for the Event object.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        viewing : str\n",
    "                        The viewing direction of the sensor.\n",
    "        bg_start : int or float, default None\n",
    "                        The start of background averaging from the start of the time series data in hours.\n",
    "        bg_length : int or float, default None\n",
    "                        The length of  the background averaging period in hours.\n",
    "        background_range : tuple or list of datetimes with len=2, default None\n",
    "                        The time range of background averaging. If defined, takes precedence over bg_start and bg_length.\n",
    "        resample_period : str, default None\n",
    "                        Pandas-compatible time string to average data. e.g. '10s' for 10 seconds or '2min' for 2 minutes.\n",
    "        channels : int or list of 2 ints, default [0,1]\n",
    "                        Index or a combination of indices to plot a channel or combination of channels.\n",
    "        yscale : str, default 'log'\n",
    "                        Matplotlib-compatible string for the scale of the y-axis. e.g. 'log' or 'linear'\n",
    "        cusum_window : int, default 30\n",
    "                        The amount of consecutive data points above the threshold before identifying an onset.\n",
    "        xlim : tuple or list, default None\n",
    "                        Panda-compatible datetimes or strings to assert the left and right boundary of the x-axis of the plot.\n",
    "        x_sigma : int, default 2\n",
    "                        The multiplier of m_d in the definition of the control parameter k in Poisson-CUSUM method.\n",
    "        \"\"\"\n",
    "\n",
    "        # This check was initially transforming the 'channels' integer to a tuple of len==1, but that\n",
    "        # raised a ValueError with solo/ept. However, a list of len==1 is somehow okay.\n",
    "        if isinstance(channels, int):\n",
    "            channels = [channels]\n",
    "\n",
    "        if (background_range is not None) and (xlim is not None):\n",
    "            # Check if background is separated from plot range by over a day, issue a warning if so, but don't\n",
    "            if (background_range[0] < xlim[0] - datetime.timedelta(days=1) and background_range[0] < xlim[1] - datetime.timedelta(days=1)) or \\\n",
    "               (background_range[1] > xlim[0] + datetime.timedelta(days=1) and background_range[1] > xlim[1] + datetime.timedelta(days=1)):\n",
    "                background_warning = \"Your background_range is separated from plot_range by over a day. If this was intentional you may ignore this warning.\"\n",
    "                # warnings.warn(message=background_warning)\n",
    "                custom_warning(message=background_warning)\n",
    "\n",
    "        if (self.spacecraft[:2].lower() == 'st' and self.sensor == 'sept') \\\n",
    "                or (self.spacecraft.lower() == 'psp' and self.sensor.startswith('isois')) \\\n",
    "                or (self.spacecraft.lower() == 'solo' and self.sensor == 'step') \\\n",
    "                or (self.spacecraft.lower() == 'solo' and self.sensor == 'ept') \\\n",
    "                or (self.spacecraft.lower() == 'solo' and self.sensor == 'het') \\\n",
    "                or (self.spacecraft.lower() == 'wind' and self.sensor == '3dp') \\\n",
    "                or (self.spacecraft.lower() == 'bepi'):\n",
    "            self.viewing_used = viewing\n",
    "            self.choose_data(viewing)\n",
    "        elif (self.spacecraft[:2].lower() == 'st' and self.sensor == 'het'):\n",
    "            self.viewing_used = ''\n",
    "        elif (self.spacecraft.lower() == 'soho' and self.sensor == 'erne'):\n",
    "            self.viewing_used = ''\n",
    "        elif (self.spacecraft.lower() == 'soho' and self.sensor in [\"ephin\", \"ephin-5\", \"ephin-15\"]):\n",
    "            self.viewing_used = ''\n",
    "\n",
    "        # Check that the data that was loaded is valid. If not, abort with warning.\n",
    "        self.validate_data()\n",
    "\n",
    "        self.averaging_used = resample_period\n",
    "        self.x_sigma = x_sigma\n",
    "\n",
    "        if self.spacecraft == 'solo':\n",
    "\n",
    "            if self.sensor == 'het':\n",
    "\n",
    "                if self.species in ['p', 'i']:\n",
    "\n",
    "                    df_flux, en_channel_string =\\\n",
    "                        self.calc_av_en_flux_HET(self.current_df_i,\n",
    "                                                 self.current_energies,\n",
    "                                                 channels)\n",
    "                elif self.species == 'e':\n",
    "\n",
    "                    df_flux, en_channel_string =\\\n",
    "                        self.calc_av_en_flux_HET(self.current_df_e,\n",
    "                                                 self.current_energies,\n",
    "                                                 channels)\n",
    "\n",
    "            elif self.sensor == 'ept':\n",
    "\n",
    "                if self.species in ['p', 'i']:\n",
    "\n",
    "                    df_flux, en_channel_string =\\\n",
    "                        self.calc_av_en_flux_EPT(self.current_df_i,\n",
    "                                                 self.current_energies,\n",
    "                                                 channels)\n",
    "                elif self.species == 'e':\n",
    "\n",
    "                    df_flux, en_channel_string =\\\n",
    "                        self.calc_av_en_flux_EPT(self.current_df_e,\n",
    "                                                 self.current_energies,\n",
    "                                                 channels)\n",
    "\n",
    "            elif self.sensor == \"step\":\n",
    "\n",
    "                if len(channels) > 1:\n",
    "                    not_implemented_msg = \"Multiple channel averaging not yet supported for STEP! Please choose only one channel.\"\n",
    "                    raise Exception(not_implemented_msg)\n",
    "\n",
    "                en_channel_string = self.get_channel_energy_values(\"str\")[channels[0]]\n",
    "\n",
    "                if self.species in ('p', 'i'):\n",
    "                    channel_id = self.current_df_i.columns[channels[0]]\n",
    "                    df_flux = pd.DataFrame(data={\n",
    "                        \"flux\": self.current_df_i[channel_id]\n",
    "                    }, index=self.current_df_i.index)\n",
    "\n",
    "                elif self.species == 'e':\n",
    "                    channel_id = self.current_df_e.columns[channels[0]]\n",
    "                    df_flux = pd.DataFrame(data={\n",
    "                        \"flux\": self.current_df_e[channel_id]\n",
    "                    }, index=self.current_df_e.index)\n",
    "\n",
    "            else:\n",
    "                invalid_sensor_msg = \"Invalid sensor!\"\n",
    "                raise Exception(invalid_sensor_msg)\n",
    "\n",
    "        if self.spacecraft[:2] == 'st':\n",
    "\n",
    "            # Super ugly implementation, but easiest to just wrap both sept and het calculators\n",
    "            # in try block. KeyError is caused by an invalid channel choice.\n",
    "            try:\n",
    "\n",
    "                if self.sensor == 'het':\n",
    "\n",
    "                    if self.species in ['p', 'i']:\n",
    "\n",
    "                        df_flux, en_channel_string =\\\n",
    "                            calc_av_en_flux_ST_HET(self.current_df_i,\n",
    "                                                   self.current_energies['channels_dict_df_p'],\n",
    "                                                   channels,\n",
    "                                                   species='p')\n",
    "                    elif self.species == 'e':\n",
    "\n",
    "                        df_flux, en_channel_string =\\\n",
    "                            calc_av_en_flux_ST_HET(self.current_df_e,\n",
    "                                                   self.current_energies['channels_dict_df_e'],\n",
    "                                                   channels,\n",
    "                                                   species='e')\n",
    "\n",
    "                elif self.sensor == 'sept':\n",
    "\n",
    "                    if self.species in ['p', 'i']:\n",
    "\n",
    "                        df_flux, en_channel_string =\\\n",
    "                            calc_av_en_flux_SEPT(self.current_df_i,\n",
    "                                                 self.current_i_energies,\n",
    "                                                 channels)\n",
    "                    elif self.species == 'e':\n",
    "\n",
    "                        df_flux, en_channel_string =\\\n",
    "                            calc_av_en_flux_SEPT(self.current_df_e,\n",
    "                                                 self.current_e_energies,\n",
    "                                                 channels)\n",
    "\n",
    "            except KeyError:\n",
    "                raise Exception(f\"{channels} is an invalid channel or a combination of channels!\")\n",
    "\n",
    "        if self.spacecraft == 'soho':\n",
    "\n",
    "            # A KeyError here is caused by invalid channel\n",
    "            try:\n",
    "\n",
    "                if self.sensor == 'erne':\n",
    "\n",
    "                    if self.species in ['p', 'i']:\n",
    "\n",
    "                        df_flux, en_channel_string =\\\n",
    "                            calc_av_en_flux_ERNE(self.current_df_i,\n",
    "                                                 self.current_energies['channels_dict_df_p'],\n",
    "                                                 channels,\n",
    "                                                 species='p',\n",
    "                                                 sensor='HET')\n",
    "\n",
    "                if self.sensor == 'ephin':\n",
    "                    # convert single-element \"channels\" list to integer\n",
    "                    if type(channels) == list:\n",
    "                        if len(channels) == 1:\n",
    "                            channels = channels[0]\n",
    "                        else:\n",
    "                            print(\"No multi-channel support for SOHO/EPHIN included yet! Select only one single channel.\")\n",
    "                    if self.species == 'e':\n",
    "                        df_flux = self.current_df_e[f'E{channels}']\n",
    "                        en_channel_string = self.current_energies[f'E{channels}']\n",
    "\n",
    "                if self.sensor in (\"ephin-5\", \"ephin-15\"):\n",
    "                    if isinstance(channels, list):\n",
    "                        if len(channels) == 1:\n",
    "                            channels = channels[0]\n",
    "                        else:\n",
    "                            raise Exception(\"No multi-channel support for SOHO/EPHIN included yet! Select only one single channel.\")\n",
    "                    if self.species == 'e':\n",
    "                        df_flux = self.current_df_e[f\"E{channels}\"]\n",
    "                        en_channel_string = self.current_energies[f\"E{channels}\"]\n",
    "\n",
    "            except KeyError:\n",
    "                raise Exception(f\"{channels} is an invalid channel or a combination of channels!\")\n",
    "\n",
    "        if self.spacecraft == 'wind':\n",
    "            if self.sensor == '3dp':\n",
    "                # convert single-element \"channels\" list to integer\n",
    "                if type(channels) == list:\n",
    "                    if len(channels) == 1:\n",
    "                        channels = channels[0]\n",
    "                    else:\n",
    "                        print(\"No multi-channel support for Wind/3DP included yet! Select only one single channel.\")\n",
    "                if self.species in ['p', 'i']:\n",
    "                    if viewing != \"omnidirectional\":\n",
    "                        df_flux = self.current_df_i.filter(like=f'FLUX_E{channels}')\n",
    "                    else:\n",
    "                        df_flux = self.current_df_i.filter(like=f'FLUX_{channels}')\n",
    "                    # extract pd.Series for further use:\n",
    "                    df_flux = df_flux[df_flux.columns[0]]\n",
    "                    # change flux units from '#/cm2-ster-eV-sec' to '#/cm2-ster-MeV-sec'\n",
    "                    df_flux = df_flux*1e6\n",
    "                    en_channel_string = self.current_i_energies['channels_dict_df']['Bins_Text'][f'ENERGY_{channels}']\n",
    "                elif self.species == 'e':\n",
    "                    if viewing != \"omnidirectional\":\n",
    "                        df_flux = self.current_df_e.filter(like=f'FLUX_E{channels}')\n",
    "                    else:\n",
    "                        df_flux = self.current_df_e.filter(like=f'FLUX_{channels}')\n",
    "                    # extract pd.Series for further use:\n",
    "                    df_flux = df_flux[df_flux.columns[0]]\n",
    "                    # change flux units from '#/cm2-ster-eV-sec' to '#/cm2-ster-MeV-sec'\n",
    "                    df_flux = df_flux*1e6\n",
    "                    en_channel_string = self.current_e_energies['channels_dict_df']['Bins_Text'][f'ENERGY_{channels}']\n",
    "\n",
    "        if self.spacecraft.lower() == 'bepi':\n",
    "            if type(channels) == list:\n",
    "                if len(channels) == 1:\n",
    "                    # convert single-element \"channels\" list to integer\n",
    "                    channels = channels[0]\n",
    "                    if self.species == 'e':\n",
    "                        df_flux = self.current_df_e[f'E{channels}']\n",
    "                        en_channel_string = self.current_energies['Energy_Bin_str'][f'E{channels}']\n",
    "                    if self.species in ['p', 'i']:\n",
    "                        df_flux = self.current_df_i[f'P{channels}']\n",
    "                        en_channel_string = self.current_energies['Energy_Bin_str'][f'P{channels}']\n",
    "                else:\n",
    "                    if self.species == 'e':\n",
    "                        df_flux, en_channel_string = calc_av_en_flux_sixs(self.current_df_e, channels, self.species)\n",
    "                    if self.species in ['p', 'i']:\n",
    "                        df_flux, en_channel_string = calc_av_en_flux_sixs(self.current_df_i, channels, self.species)\n",
    "\n",
    "        if self.spacecraft.lower() == 'psp':\n",
    "            if self.sensor.lower() == 'isois-epihi':\n",
    "                if self.species in ['p', 'i']:\n",
    "                    # We're using here only the HET instrument of EPIHI (and not LET1 or LET2)\n",
    "                    df_flux, en_channel_string =\\\n",
    "                        calc_av_en_flux_PSP_EPIHI(df=self.current_df_i,\n",
    "                                                  energies=self.current_i_energies,\n",
    "                                                  en_channel=channels,\n",
    "                                                  species='p',\n",
    "                                                  instrument='het',\n",
    "                                                  viewing=viewing.upper())\n",
    "                if self.species == 'e':\n",
    "                    # We're using here only the HET instrument of EPIHI (and not LET1 or LET2)\n",
    "                    df_flux, en_channel_string =\\\n",
    "                        calc_av_en_flux_PSP_EPIHI(df=self.current_df_e,\n",
    "                                                  energies=self.current_e_energies,\n",
    "                                                  en_channel=channels,\n",
    "                                                  species='e',\n",
    "                                                  instrument='het',\n",
    "                                                  viewing=viewing.upper())\n",
    "            if self.sensor.lower() == 'isois-epilo':\n",
    "                if self.species == 'e':\n",
    "                    # We're using here only the F channel of EPILO (and not E or G)\n",
    "                    df_flux, en_channel_string =\\\n",
    "                        calc_av_en_flux_PSP_EPILO(df=self.current_df_e,\n",
    "                                                  en_dict=self.current_e_energies,\n",
    "                                                  en_channel=channels,\n",
    "                                                  species='e',\n",
    "                                                  mode='pe',\n",
    "                                                  chan='F',\n",
    "                                                  viewing=viewing)\n",
    "\n",
    "        if resample_period is not None:\n",
    "\n",
    "            df_averaged = resample_df(df=df_flux, resample=resample_period)\n",
    "\n",
    "        else:\n",
    "\n",
    "            df_averaged = df_flux\n",
    "\n",
    "        flux_series, onset_stats, onset_found, peak_flux, peak_time, fig, bg_mean =\\\n",
    "            self.onset_analysis(df_averaged, bg_start, bg_length, background_range,\n",
    "                                en_channel_string, yscale=yscale, cusum_window=cusum_window, xlim=xlim)\n",
    "\n",
    "        # At least in the case of solo/ept the peak_flux is a pandas Dataframe, but it should be a Series\n",
    "        if isinstance(peak_flux, pd.core.frame.DataFrame):\n",
    "            peak_flux = pd.Series(data=peak_flux.values[0])\n",
    "\n",
    "        # update class attributes before returning variables:\n",
    "        self.update_onset_attributes(flux_series, onset_stats, onset_found, peak_flux.values[0], peak_time, fig, bg_mean)\n",
    "\n",
    "        return flux_series, onset_stats, onset_found, peak_flux, peak_time, fig, bg_mean\n",
    "\n",
    "    # For backwards compatibility, make a copy of the `find_onset` function that is called `analyse` (which was its old name).\n",
    "    # analyse = copy.copy(find_onset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks-CgLsohj7-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
