{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading data to InfluxDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "1. [InfluxDB installed](https://www.influxdata.com/downloads/).\n",
    "2. Export InfluxDB API Key as `INFLUXDB_TOKEN` environment variable.\n",
    "3. Download preprocessed CSV data using `../scripts/fetch_data.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import influxdb_client\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the InfluxDB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PREROCESSED_DIR = \"../data_processed\"\n",
    "DATA_PREPROCESSED_FILE = DATA_PREROCESSED_DIR + \"/preprocessed.csv\"\n",
    "\n",
    "bucket = \"radem\"\n",
    "org = \"radem\"\n",
    "token = os.environ.get(\"INFLUXDB_TOKEN\")\n",
    "url=\"http://localhost:8086\"\n",
    "\n",
    "client = influxdb_client.InfluxDBClient(\n",
    "    url=url,\n",
    "    token=token,\n",
    "    org=org\n",
    ")\n",
    "\n",
    "write_api = client.write_api(write_options=SYNCHRONOUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading preprocessed CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>channel</th>\n",
       "      <th>value</th>\n",
       "      <th>time_ns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-11 00:00:32.787951</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1696982432787951000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-11 00:00:32.787951</td>\n",
       "      <td>e</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1696982432787951000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-11 00:00:32.787951</td>\n",
       "      <td>e</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1696982432787951000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-11 00:00:32.787951</td>\n",
       "      <td>e</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1696982432787951000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-11 00:00:32.787951</td>\n",
       "      <td>e</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>1696982432787951000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21613307</th>\n",
       "      <td>2023-10-06 23:59:23.156658</td>\n",
       "      <td>d</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1696636763156658000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21613308</th>\n",
       "      <td>2023-10-06 23:59:23.156658</td>\n",
       "      <td>d</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1696636763156658000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21613309</th>\n",
       "      <td>2023-10-06 23:59:23.156658</td>\n",
       "      <td>d</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1696636763156658000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21613310</th>\n",
       "      <td>2023-10-06 23:59:23.156658</td>\n",
       "      <td>d</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>1696636763156658000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21613311</th>\n",
       "      <td>2023-10-06 23:59:23.156658</td>\n",
       "      <td>d</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1696636763156658000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613312 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                time event_type  channel  value  \\\n",
       "0         2023-10-11 00:00:32.787951          e        1      6   \n",
       "1         2023-10-11 00:00:32.787951          e        2     12   \n",
       "2         2023-10-11 00:00:32.787951          e        3     14   \n",
       "3         2023-10-11 00:00:32.787951          e        4     16   \n",
       "4         2023-10-11 00:00:32.787951          e        5     15   \n",
       "...                              ...        ...      ...    ...   \n",
       "21613307  2023-10-06 23:59:23.156658          d       27      1   \n",
       "21613308  2023-10-06 23:59:23.156658          d       28      3   \n",
       "21613309  2023-10-06 23:59:23.156658          d       29      0   \n",
       "21613310  2023-10-06 23:59:23.156658          d       30      1   \n",
       "21613311  2023-10-06 23:59:23.156658          d       31      0   \n",
       "\n",
       "                      time_ns  \n",
       "0         1696982432787951000  \n",
       "1         1696982432787951000  \n",
       "2         1696982432787951000  \n",
       "3         1696982432787951000  \n",
       "4         1696982432787951000  \n",
       "...                       ...  \n",
       "21613307  1696636763156658000  \n",
       "21613308  1696636763156658000  \n",
       "21613309  1696636763156658000  \n",
       "21613310  1696636763156658000  \n",
       "21613311  1696636763156658000  \n",
       "\n",
       "[21613312 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PREPROCESSED_FILE)\n",
    "\n",
    "# Convert time to ns for InfluxDB\n",
    "df['time_ns'] = pd.to_datetime(df['time'], format=\"%Y-%m-%d %H:%M:%S.%f\").astype('int64')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to InfluxDB Line Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH_SIZE = 1000000\n",
      "INPUT_SIZE = 21613312\n",
      "Processing batch of 1000000 records, from 0 to 999999.\n",
      "Processing batch of 1000000 records, from 1000000 to 1999999.\n",
      "Processing batch of 1000000 records, from 2000000 to 2999999.\n",
      "Processing batch of 1000000 records, from 3000000 to 3999999.\n",
      "Processing batch of 1000000 records, from 4000000 to 4999999.\n",
      "Processing batch of 1000000 records, from 5000000 to 5999999.\n",
      "Processing batch of 1000000 records, from 6000000 to 6999999.\n",
      "Processing batch of 1000000 records, from 7000000 to 7999999.\n",
      "Processing batch of 1000000 records, from 8000000 to 8999999.\n",
      "Processing batch of 1000000 records, from 9000000 to 9999999.\n",
      "Processing batch of 1000000 records, from 10000000 to 10999999.\n",
      "Processing batch of 1000000 records, from 11000000 to 11999999.\n",
      "Processing batch of 1000000 records, from 12000000 to 12999999.\n",
      "Processing batch of 1000000 records, from 13000000 to 13999999.\n",
      "Processing batch of 1000000 records, from 14000000 to 14999999.\n",
      "Processing batch of 1000000 records, from 15000000 to 15999999.\n",
      "Processing batch of 1000000 records, from 16000000 to 16999999.\n",
      "Processing batch of 1000000 records, from 17000000 to 17999999.\n",
      "Processing batch of 1000000 records, from 18000000 to 18999999.\n",
      "Processing batch of 1000000 records, from 19000000 to 19999999.\n",
      "Processing batch of 1000000 records, from 20000000 to 20999999.\n",
      "Processing batch of 613312 records, from 21000000 to 21613311.\n",
      "Processed 21613312 records in 26.304991 seconds\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000000\n",
    "\n",
    "print(f\"BATCH_SIZE = {batch_size}\")\n",
    "print(f\"INPUT_SIZE = {len(df)}\")\n",
    "\n",
    "time_start = pd.Timestamp.now()\n",
    "count = 0\n",
    "for batch in range(0, len(df), batch_size):    \n",
    "    batch_end = min(batch+batch_size-1, len(df)-1)\n",
    "    batch_indices = slice(batch, batch_end)\n",
    "\n",
    "    print(f\"Processing batch of {batch_indices.stop - batch_indices.start + 1} records, from {batch_indices.start} to {batch_indices.stop}.\")\n",
    "\n",
    "    # Convert time to datetime and then to timestamp in nanoseconds\n",
    "    df.loc[batch_indices, 'timestamp'] = pd.to_datetime(df.loc[batch_indices, 'time']).astype('int64')\n",
    "\n",
    "    # Use vectorized operations to construct the line\n",
    "    df.loc[batch_indices, 'line'] = (\n",
    "        \"my_measurement,\" +\n",
    "        \"event_type=\" + df.loc[batch_indices, 'event_type'] + \",\" +\n",
    "        \"channel=\" + df.loc[batch_indices, 'channel'].astype(str) + \" \" +\n",
    "        \"value=\" + df.loc[batch_indices, 'value'].astype(str) + \"i \" +\n",
    "        df.loc[batch_indices, 'time_ns'].astype(str)\n",
    "    )\n",
    "\n",
    "    count += len(df.loc[batch_indices, 'line'])\n",
    "\n",
    "time_total = pd.Timestamp.now() - time_start\n",
    "print(f\"Processed {count} records in {time_total.total_seconds()} seconds\")\n",
    "print(f\"SUCCESS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to InfluxDB Line Protocol file\n",
    "\n",
    "Example line: `my_measurement,event_type=e,channel=0 value=123 1556813561098000000`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['line'].to_csv(DATA_PREROCESSED_DIR + \"/influx_line_protocol.line\", index=False, header=False, quoting=csv.QUOTE_NONE, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from InfluxDB Line Protocol file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lines = pd.read_csv(DATA_PREROCESSED_DIR + \"/influx_line_protocol.line\", header=None, sep='\\0', names=['line'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to InfluxDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading batch of 1000000 records, from 0 to 999999.\n",
      "Uploading batch of 1000000 records, from 1000000 to 1999999.\n",
      "Uploading batch of 1000000 records, from 2000000 to 2999999.\n",
      "Uploading batch of 1000000 records, from 3000000 to 3999999.\n",
      "Uploading batch of 1000000 records, from 4000000 to 4999999.\n",
      "Uploading batch of 1000000 records, from 5000000 to 5999999.\n",
      "Uploading batch of 1000000 records, from 6000000 to 6999999.\n",
      "Uploading batch of 1000000 records, from 7000000 to 7999999.\n",
      "Uploading batch of 1000000 records, from 8000000 to 8999999.\n",
      "Uploading batch of 1000000 records, from 9000000 to 9999999.\n",
      "Uploading batch of 1000000 records, from 10000000 to 10999999.\n",
      "Uploading batch of 1000000 records, from 11000000 to 11999999.\n",
      "Uploading batch of 1000000 records, from 12000000 to 12999999.\n",
      "Uploading batch of 1000000 records, from 13000000 to 13999999.\n",
      "Uploading batch of 1000000 records, from 14000000 to 14999999.\n",
      "Uploading batch of 1000000 records, from 15000000 to 15999999.\n",
      "Uploading batch of 1000000 records, from 16000000 to 16999999.\n",
      "Uploading batch of 1000000 records, from 17000000 to 17999999.\n",
      "Uploading batch of 1000000 records, from 18000000 to 18999999.\n",
      "Uploading batch of 1000000 records, from 19000000 to 19999999.\n",
      "Uploading batch of 1000000 records, from 20000000 to 20999999.\n",
      "Uploading batch of 613312 records, from 21000000 to 21613311.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000000\n",
    "for batch in range(0, len(df_lines), batch_size):\n",
    "    batch_end = min(batch+batch_size-1, len(df_lines)-1)\n",
    "    batch_indices = slice(batch, batch_end)\n",
    "\n",
    "    print(f\"Uploading batch of {batch_indices.stop - batch_indices.start + 1} records, from {batch_indices.start} to {batch_indices.stop}.\")\n",
    "\n",
    "    write_api.write(bucket, org, df_lines.loc[batch_indices, 'line'])\n",
    "\n",
    "write_api.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
