{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 3: Processing Line Protocol & uploading to InfluxDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "1. [InfluxDB installed](https://www.influxdata.com/downloads/).\n",
    "2. Export InfluxDB API Key in `.env` file.\n",
    "3. Prepare preprocessed CSV data using previous notebook or other tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ../data/line_protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import influxdb_client\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "\n",
    "DATA_PREROCESSED_DIR = Path(\"../data/csv\")\n",
    "DATA_LINE_PROTOCOL_DIR = Path(\"../data/line_protocol\")\n",
    "\n",
    "TOKEN = os.environ.get(\"INFLUXDB_TOKEN\")\n",
    "URL = \"http://localhost:8086\"\n",
    "ORG = \"radem\"\n",
    "\n",
    "BUCKET = \"radem\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the InfluxDB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_write_api(url: str = URL, token: str = TOKEN, org: str = ORG):\n",
    "    client = influxdb_client.InfluxDBClient(\n",
    "        url=url,\n",
    "        token=token,\n",
    "        org=org\n",
    "    )\n",
    "\n",
    "    write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "\n",
    "    return write_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading preprocessed CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_temperature(filename: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(str(filename))\n",
    "\n",
    "    # Convert time\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "    # Convert time to ns for InfluxDB\n",
    "    df['time_ns'] = pd.to_datetime(df['time']).astype('int64')\n",
    "\n",
    "    # Convert temperatures to int\n",
    "    df[\"CEU Temperature (1)\"] = df[\"CEU Temperature (1)\"].astype(\"int64\")\n",
    "    df[\"P&IDH Temperature (2)\"] = df[\"P&IDH Temperature (2)\"].astype(\"int64\")\n",
    "    df[\"EDH Temperature (3)\"] = df[\"EDH Temperature (3)\"].astype(\"int64\")\n",
    "    df[\"DDH Temperature (4)\"] = df[\"DDH Temperature (4)\"].astype(\"int64\")\n",
    "    df[\"PCU Temperature (5)\"] = df[\"PCU Temperature (5)\"].astype(\"int64\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def read_particles(filename: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(str(filename))\n",
    "\n",
    "    # Convert time\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "    # Convert time to ns for InfluxDB\n",
    "    df['time_ns'] = pd.to_datetime(df['time']).astype('int64')\n",
    "\n",
    "    # Converts\n",
    "    df[\"bin\"] = df[\"bin\"].astype(\"int8\")\n",
    "    df[\"value\"] = df[\"value\"].astype(\"int64\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def read_flux(filename: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(str(filename))\n",
    "\n",
    "    # Convert time\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "\n",
    "    # Convert time to ns for InfluxDB\n",
    "    df['time_ns'] = pd.to_datetime(df['time']).astype('int64')\n",
    "\n",
    "    # Converts\n",
    "    df[\"value\"] = df[\"value\"].astype(\"int64\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting DataFrame -> Line Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_temp_to_line_protocol(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    measurements = [\n",
    "        \"temp1_ceu\",\n",
    "        \"temp2_pidh\",\n",
    "        \"temp3_edh\",\n",
    "        \"temp4_ddh\",\n",
    "        \"temp5_pcu\"\n",
    "    ]\n",
    "\n",
    "    labels = [\n",
    "        \"CEU Temperature (1)\",\n",
    "        \"P&IDH Temperature (2)\",\n",
    "        \"EDH Temperature (3)\",\n",
    "        \"DDH Temperature (4)\",\n",
    "        \"PCU Temperature (5)\"\n",
    "    ]\n",
    "    \n",
    "    df = pd.concat((\n",
    "        pd.DataFrame(\n",
    "            measurement + \" \" + \n",
    "            \"value=\" + df[label].astype(str) + \"i \" + \n",
    "            df['time_ns'].astype(str),\n",
    "            columns=[\"line\"]\n",
    "        )\n",
    "        for measurement, label in zip(measurements, labels)\n",
    "    ), ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def convert_particles_to_line_protocol(df: pd.DataFrame, measurement_name: str) -> pd.DataFrame:\n",
    "    df = pd.DataFrame(\n",
    "        measurement_name + \n",
    "        \",bin=\" + df[\"bin\"].astype(str) + \" \" \n",
    "        \"value=\" + df[\"value\"].astype(str) + \"i \" + \n",
    "        df['time_ns'].astype(str),\n",
    "        columns=[\"line\"]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def convert_flux_to_line_protocol(df: pd.DataFrame, measurement_name: str) -> pd.DataFrame:\n",
    "    df = pd.DataFrame(\n",
    "        measurement_name + \n",
    "        \" \" + \n",
    "        \"value=\" + df[\"value\"].astype(str) + \"i \" + \n",
    "        df['time_ns'].astype(str),\n",
    "        columns=[\"line\"]\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Line Protocol file\n",
    "\n",
    "Example line: `my_measurement,event_type=e,channel=0 value=123 1556813561098000000`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_line_protocol(df: pd.DataFrame, filename: Path):\n",
    "    df.to_csv(filename, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Line Protocol file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_line_protocol(filename: Path) -> pd.DataFrame:\n",
    "    return pd.read_csv(\n",
    "        str(filename), \n",
    "        header=None, \n",
    "        sep='\\0', \n",
    "        names=['line']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to InfluxDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_line_protocol(\n",
    "        write_api: influxdb_client.WriteApi, \n",
    "        df_lines: pd.DataFrame,\n",
    "        bucket: str,\n",
    "        org: str, \n",
    "        batch_size: int = 1000000) -> None:\n",
    "    for batch in range(0, len(df_lines), batch_size):\n",
    "        batch_end = min(batch + batch_size - 1, len(df_lines) - 1)\n",
    "        batch_indices = slice(batch, batch_end)\n",
    "\n",
    "        print(f\"Uploading batch of {batch_indices.stop - batch_indices.start + 1} records, from {batch_indices.start} to {batch_indices.stop}.\")\n",
    "\n",
    "        write_api.write(bucket, org, df_lines.loc[batch_indices, 'line'])\n",
    "\n",
    "    write_api.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. get the newest CSV filename\n",
    "csv_filename = sorted(DATA_PREROCESSED_DIR.glob(\"temperature_*.csv\"))[-1]\n",
    "\n",
    "# 2. read the CSV file\n",
    "df = read_temperature(csv_filename)\n",
    "\n",
    "# 3. convert the CSV file to line protocol\n",
    "df_lines = convert_temp_to_line_protocol(df)\n",
    "\n",
    "# 4. (optional) save the line protocol to a file\n",
    "line_protocol_filename = DATA_LINE_PROTOCOL_DIR / f\"{csv_filename.stem}.line\"\n",
    "save_line_protocol(df_lines, line_protocol_filename)\n",
    "\n",
    "# 5. upload the line protocol to InfluxDB\n",
    "write_api = get_write_api(\n",
    "    url=URL, \n",
    "    token=TOKEN, \n",
    "    org=ORG)\n",
    "\n",
    "upload_line_protocol(\n",
    "    write_api=write_api, \n",
    "    df_lines=df_lines, \n",
    "    bucket=BUCKET, \n",
    "    org=ORG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for particle in [\"protons\", \"electrons\", \"dd\", \"heavy_ions\"]:\n",
    "    print(f\"Uploading {particle} data...\")\n",
    "\n",
    "    # 1. get the newest CSV filename\n",
    "    csv_filename = sorted(DATA_PREROCESSED_DIR.glob(f\"{particle}_2*.csv\"))[-1]\n",
    "\n",
    "    # 2. read the CSV file\n",
    "    df = read_particles(csv_filename)\n",
    "    print(f\"Read {len(df)} records from {csv_filename}\")\n",
    "\n",
    "    # 3. convert the CSV file to line protocol\n",
    "    df_lines = convert_particles_to_line_protocol(df, particle)\n",
    "\n",
    "    # 4. (optional) save the line protocol to a file\n",
    "    line_protocol_filename = DATA_LINE_PROTOCOL_DIR / f\"{csv_filename.stem}.line\"\n",
    "    save_line_protocol(df_lines, line_protocol_filename)\n",
    "\n",
    "    # 5. upload the line protocol to InfluxDB\n",
    "    write_api = get_write_api(\n",
    "        url=URL, \n",
    "        token=TOKEN, \n",
    "        org=ORG)\n",
    "\n",
    "    upload_line_protocol(\n",
    "        write_api=write_api, \n",
    "        df_lines=df_lines, \n",
    "        bucket=BUCKET, \n",
    "        org=ORG)\n",
    "    \n",
    "    write_api.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for particle in [\"protons_flux\", \"electrons_flux\", \"dd_flux\"]:\n",
    "    print(f\"Uploading {particle} data...\")\n",
    "\n",
    "    # 1. get the newest CSV filename\n",
    "    csv_filename = sorted(DATA_PREROCESSED_DIR.glob(f\"{particle}_*.csv\"))[-1]\n",
    "\n",
    "    # 2. read the CSV file\n",
    "    df = read_flux(csv_filename)\n",
    "    print(f\"Read {len(df)} records from {csv_filename}\")\n",
    "\n",
    "    # 3. convert the CSV file to line protocol\n",
    "    df_lines = convert_flux_to_line_protocol(df, particle)\n",
    "\n",
    "    # 4. (optional) save the line protocol to a file\n",
    "    line_protocol_filename = DATA_LINE_PROTOCOL_DIR / f\"{csv_filename.stem}.line\"\n",
    "    save_line_protocol(df_lines, line_protocol_filename)\n",
    "\n",
    "    # 5. upload the line protocol to InfluxDB\n",
    "    write_api = get_write_api(\n",
    "        url=URL, \n",
    "        token=TOKEN, \n",
    "        org=ORG)\n",
    "\n",
    "    upload_line_protocol(\n",
    "        write_api=write_api, \n",
    "        df_lines=df_lines, \n",
    "        bucket=BUCKET, \n",
    "        org=ORG)\n",
    "    \n",
    "    write_api.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
